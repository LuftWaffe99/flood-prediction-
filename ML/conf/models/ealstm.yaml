# --- Experiment configurations --------------------------------------------------------------------

# experiment name, used as folder name
experiment_name: ealstm

# fixed seed, leave empty to use a random seed
seed: 42

# --- Model configuration --------------------------------------------------------------------------

# base model type [lstm, ealstm, cudalstm, embcudalstm, shortcutlstm, dropoutlstm, cudalstminitialh]
# (has to match the if statement in modelzoo/__init__.py)
model: ealstm

output_activation: linear

head: "regression"

hidden_size: 128

initial_forget_bias: 3

output_dropout: 0.3


# --- Training configuration -----------------------------------------------------------------------

# specify optimizer [Adam, AdamW, Adadelta]
optimizer: Adam

# specify loss [MSE, NSE, RMSE, UMALLoss, MDNLoss]
loss: NSE

# specify learning rates to use starting at specific epochs (0 is the initial learning rate)
learning_rate:
  0: 1e-2
  1: 1e-2
  10: 1e-3
  20: 1e-4

# Mini-batch size
batch_size: 2048

# Number of training epochs
epochs: 30

# Length of the input sequence
seq_length: 365


# --- Data configurations --------------------------------------------------------------------------

# specify dataset version [camels_kz, fancy_dataset, sigma]
dataset: sigma


# --- Side configurations --------------------------------------------------------------------------

wandb: True

discharge: True

gpu: 0


# --- Hydra configurations -------------------------------------------------------------------------

defaults:
  - _self_
  # - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled 


hydra:
  verbose: True
  sweeper:
    params:
      seed: 18,29
      hidden_size: 32,64,128,256
      seq_length: 180,270,365
      optimizer: Adam,AdamW
      output_dropout: 0.3,0.4

  output_subdir: null  
  run:  
    dir: .
