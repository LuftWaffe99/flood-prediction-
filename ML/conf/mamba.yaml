# --- Experiment configurations --------------------------------------------------------------------

# experiment name, used as folder name
experiment_name: mamba


# --- Model configuration --------------------------------------------------------------------------

# base model type [lstm, ealstm, cudalstm, embcudalstm, shortcutlstm, dropoutlstm, cudalstminitialh]
# (has to match the if statement in modelzoo/__init__.py)
model: mamba

# statics_embedding:
#   type: fc
#   hiddens: 
#     - 32
#     - 20
#     - 64
#   activation: tanh
#   dropout: 0.0


# dynamics_embedding:
#   type: fc
#   # define number of neurons per layer in the FC network used as embedding network
#   hiddens:
#     - 32
#     - 20
#     - 64
#   # activation function of embedding network
#   activation: tanh
#   # dropout applied to embedding network
#   dropout: 0.0


output_activation: linear

head: "regression"

mamba_d_state: 32
mamba_d_conv: 8
mamba_expand: 2

hidden_size: 64


# --- Training configuration -----------------------------------------------------------------------

# specify optimizer [Adam, AdamW, Adadelta]
optimizer: Adam

# specify loss [MSE, NSE, RMSE, UMALLoss, MDNLoss]
loss: NSE

# specify learning rates to use starting at specific epochs (0 is the initial learning rate)
learning_rate:
  0: 1e-3
  1: 1e-3
  5: 1e-4
  10: 1e-5

# Mini-batch size
batch_size: 2048

# Number of training epochs
epochs: 4

# Length of the input sequence
seq_length: 365


# --- Data configurations --------------------------------------------------------------------------

# specify dataset version [camels_kz, fancy_dataset]
dataset: fancy


# --- Side configurations --------------------------------------------------------------------------

wandb: False

gpu: 0


# --- Hydra configurations -------------------------------------------------------------------------

defaults:
  - _self_
  # - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled 


hydra:
  verbose: True
  sweeper:
    params:
      mamba_d_state: 32,64,128
      mamba_d_conv: 4,8,64
      mamba_expand: 1,2,4
      hidden_size: 64,128,256

  output_subdir: null  
  run:  
    dir: .