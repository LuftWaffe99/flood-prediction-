{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/raw era5/'\n",
    "gsmap_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/GSMAP/'\n",
    "chirps_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/chirps/'\n",
    "fancy_dir = 'C:/Users/User\\Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/fancy_dataset/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11001 is DONE\n",
      "11063 is DONE\n",
      "11068 is DONE\n",
      "11077 is DONE\n",
      "11090 is DONE\n",
      "11094 is DONE\n",
      "11108 is DONE\n",
      "11117 is DONE\n",
      "11124 is DONE\n",
      "11126 is DONE\n",
      "11129 is DONE\n",
      "11131 is DONE\n",
      "11137 is DONE\n",
      "11139 is DONE\n",
      "11143 is DONE\n",
      "11146 is DONE\n",
      "11147 is DONE\n",
      "11157 is DONE\n",
      "11160 is DONE\n",
      "11163 is DONE\n",
      "11164 is DONE\n",
      "11170 is DONE\n",
      "11187 is DONE\n",
      "11188 is DONE\n",
      "11189 is DONE\n",
      "11199 is DONE\n",
      "11207 is DONE\n",
      "11219 is DONE\n",
      "11233 is DONE\n",
      "11242 is DONE\n",
      "11272 is DONE\n",
      "11275 is DONE\n",
      "11291 is DONE\n",
      "11293 is DONE\n",
      "11395 is DONE\n",
      "11397 is DONE\n",
      "11421 is DONE\n",
      "11424 is DONE\n",
      "11432 is DONE\n",
      "11433 is DONE\n",
      "11453 is DONE\n",
      "11461 is DONE\n",
      "11468 is DONE\n",
      "11469 is DONE\n",
      "11661 is DONE\n",
      "12001 is DONE\n",
      "12002 is DONE\n",
      "12008 is DONE\n",
      "12029 is DONE\n",
      "12031 is DONE\n",
      "12032 is DONE\n",
      "12072 is DONE\n",
      "12075 is DONE\n",
      "12564 is DONE\n",
      "13002 is DONE\n",
      "13005 is DONE\n",
      "13016 is DONE\n",
      "13029 is DONE\n",
      "13035 is DONE\n",
      "13038 is DONE\n",
      "13048 is DONE\n",
      "13061 is DONE\n",
      "13064 is DONE\n",
      "13090 is DONE\n",
      "13091 is DONE\n",
      "13095 is DONE\n",
      "13105 is DONE\n",
      "13115 is DONE\n",
      "13128 is DONE\n",
      "13142 is DONE\n",
      "13148 is DONE\n",
      "13198 is DONE\n",
      "13201 is DONE\n",
      "13221 is DONE\n",
      "19010 is DONE\n",
      "19013 is DONE\n",
      "19021 is DONE\n",
      "19022 is DONE\n",
      "19033 is DONE\n",
      "19034 is DONE\n",
      "19130 is DONE\n",
      "19180 is DONE\n",
      "19195 is DONE\n",
      "19196 is DONE\n",
      "19205 is DONE\n",
      "19208 is DONE\n",
      "19211 is DONE\n",
      "19218 is DONE\n",
      "19220 is DONE\n",
      "19229 is DONE\n",
      "19239 is DONE\n",
      "19240 is DONE\n",
      "19243 is DONE\n",
      "19246 is DONE\n",
      "19247 is DONE\n",
      "19255 is DONE\n",
      "19257 is DONE\n",
      "19289 is DONE\n",
      "19300 is DONE\n",
      "19301 is DONE\n",
      "19302 is DONE\n",
      "19462 is DONE\n",
      "19463 is DONE\n",
      "77818 is DONE\n",
      "77819 is DONE\n",
      "77895 is DONE\n"
     ]
    }
   ],
   "source": [
    "for dataframe in os.listdir(era_dir):\n",
    "    mydf = pd.DataFrame()\n",
    "    # loading era5 raw data \n",
    "    eradf = pd.read_csv(era_dir + dataframe, parse_dates=['date'])\n",
    "    mydf['basin_id'] = eradf['basin_id']\n",
    "    mydf['date'] = eradf['date']\n",
    "    mydf['prcp_era'] = eradf['prcp'] * 1000  # for some reason ERA computes prcp in m not mm\n",
    "    mydf['temp_mean'] = eradf['temp_mean'] - 273.15 # from Kelvin to Celcius\n",
    "    mydf['temp_min'] = eradf['temp_min'] - 273.15\n",
    "    mydf['temp_max'] = eradf['temp_max'] - 273.15\n",
    "    mydf['vp1'] = 0.1 * (eradf['dew_mean'] ** -4.9283) * (10 ** (23.5518 + (-2937.4 / eradf['dew_mean']))) # Dr. Vadim provided this formula\n",
    "    mydf['dew_mean'] = eradf['dew_mean'] - 273.15\n",
    "    mydf['wind_speed'] = (eradf['u_comp_wind'] ** 2 + eradf['v_comp_wind'] ** 2) ** 0.5 # Dr. Vadim provided this formula\n",
    "    mydf['vp2'] = 0.6108 * np.exp(17.27 * mydf['dew_mean'] / (mydf['dew_mean'] + 237.3)) # Dr. Vadim provided this formula \n",
    "    mydf['srad_joules'] = eradf['srad_joules']\n",
    "\n",
    "    # print(mydf)\n",
    "    # print(fancy_dir + dataframe.split('_')[1][:5])\n",
    "    # break\n",
    "\n",
    "    mydf[['basin_id', 'date', 'prcp_era', 'temp_mean', 'temp_min', 'temp_max', 'dew_mean', 'wind_speed', 'vp1', 'vp2', 'srad_joules']].to_csv(fancy_dir + dataframe.split('_')[1][:5] + '.csv', index=False)\n",
    "    print(dataframe.split('_')[1][:5] + ' is DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "11001.csv is DONE\n",
      "\n",
      "\n",
      "11063.csv is DONE\n",
      "\n",
      "\n",
      "11068.csv is DONE\n",
      "\n",
      "\n",
      "11077.csv is DONE\n",
      "\n",
      "\n",
      "11090.csv is DONE\n",
      "\n",
      "\n",
      "11094.csv is DONE\n",
      "\n",
      "\n",
      "11108.csv is DONE\n",
      "\n",
      "\n",
      "11117.csv is DONE\n",
      "\n",
      "\n",
      "11124.csv is DONE\n",
      "\n",
      "\n",
      "11126.csv is DONE\n",
      "\n",
      "\n",
      "11129.csv is DONE\n",
      "\n",
      "\n",
      "11131.csv is DONE\n",
      "\n",
      "\n",
      "11137.csv is DONE\n",
      "\n",
      "\n",
      "11139.csv is DONE\n",
      "\n",
      "\n",
      "11143.csv is DONE\n",
      "\n",
      "\n",
      "11146.csv is DONE\n",
      "\n",
      "\n",
      "11147.csv is DONE\n",
      "\n",
      "\n",
      "11157.csv is DONE\n",
      "\n",
      "\n",
      "11160.csv is DONE\n",
      "\n",
      "\n",
      "11163.csv is DONE\n",
      "\n",
      "\n",
      "11164.csv is DONE\n",
      "\n",
      "\n",
      "11170.csv is DONE\n",
      "\n",
      "\n",
      "11187.csv is DONE\n",
      "\n",
      "\n",
      "11188.csv is DONE\n",
      "\n",
      "\n",
      "11189.csv is DONE\n",
      "\n",
      "\n",
      "11199.csv is DONE\n",
      "\n",
      "\n",
      "11207.csv is DONE\n",
      "\n",
      "\n",
      "11219.csv is DONE\n",
      "\n",
      "\n",
      "11233.csv is DONE\n",
      "\n",
      "\n",
      "11242.csv is DONE\n",
      "\n",
      "\n",
      "11272.csv is DONE\n",
      "\n",
      "\n",
      "11275.csv is DONE\n",
      "\n",
      "\n",
      "11291.csv is DONE\n",
      "\n",
      "\n",
      "11293.csv is DONE\n",
      "\n",
      "\n",
      "11395.csv is DONE\n",
      "\n",
      "\n",
      "11397.csv is DONE\n",
      "\n",
      "\n",
      "11421.csv is DONE\n",
      "\n",
      "\n",
      "11424.csv is DONE\n",
      "\n",
      "\n",
      "11432.csv is DONE\n",
      "\n",
      "\n",
      "11433.csv is DONE\n",
      "\n",
      "\n",
      "11453.csv is DONE\n",
      "\n",
      "\n",
      "11461.csv is DONE\n",
      "\n",
      "\n",
      "11468.csv is DONE\n",
      "\n",
      "\n",
      "11469.csv is DONE\n",
      "\n",
      "\n",
      "11661.csv is DONE\n",
      "\n",
      "\n",
      "12001.csv is DONE\n",
      "\n",
      "\n",
      "12002.csv is DONE\n",
      "\n",
      "\n",
      "12008.csv is DONE\n",
      "\n",
      "\n",
      "12029.csv is DONE\n",
      "\n",
      "\n",
      "12031.csv is DONE\n",
      "\n",
      "\n",
      "12032.csv is DONE\n",
      "\n",
      "\n",
      "12072.csv is DONE\n",
      "\n",
      "\n",
      "12075.csv is DONE\n",
      "\n",
      "\n",
      "12564.csv is DONE\n",
      "\n",
      "\n",
      "13002.csv is DONE\n",
      "\n",
      "\n",
      "13005.csv is DONE\n",
      "\n",
      "\n",
      "13016.csv is DONE\n",
      "\n",
      "\n",
      "13029.csv is DONE\n",
      "\n",
      "\n",
      "13035.csv is DONE\n",
      "\n",
      "\n",
      "13038.csv is DONE\n",
      "\n",
      "\n",
      "13048.csv is DONE\n",
      "\n",
      "\n",
      "13061.csv is DONE\n",
      "\n",
      "\n",
      "13064.csv is DONE\n",
      "\n",
      "\n",
      "13090.csv is DONE\n",
      "\n",
      "\n",
      "13091.csv is DONE\n",
      "\n",
      "\n",
      "13095.csv is DONE\n",
      "\n",
      "\n",
      "13105.csv is DONE\n",
      "\n",
      "\n",
      "13115.csv is DONE\n",
      "\n",
      "\n",
      "13128.csv is DONE\n",
      "\n",
      "\n",
      "13142.csv is DONE\n",
      "\n",
      "\n",
      "13148.csv is DONE\n",
      "\n",
      "\n",
      "13198.csv is DONE\n",
      "\n",
      "\n",
      "13201.csv is DONE\n",
      "\n",
      "\n",
      "13221.csv is DONE\n",
      "\n",
      "\n",
      "19010.csv is DONE\n",
      "\n",
      "\n",
      "19013.csv is DONE\n",
      "\n",
      "\n",
      "19021.csv is DONE\n",
      "\n",
      "\n",
      "19022.csv is DONE\n",
      "\n",
      "\n",
      "19033.csv is DONE\n",
      "\n",
      "\n",
      "19034.csv is DONE\n",
      "\n",
      "\n",
      "19130.csv is DONE\n",
      "\n",
      "\n",
      "19180.csv is DONE\n",
      "\n",
      "\n",
      "19195.csv is DONE\n",
      "\n",
      "\n",
      "19196.csv is DONE\n",
      "\n",
      "\n",
      "19205.csv is DONE\n",
      "\n",
      "\n",
      "19208.csv is DONE\n",
      "\n",
      "\n",
      "19211.csv is DONE\n",
      "\n",
      "\n",
      "19218.csv is DONE\n",
      "\n",
      "\n",
      "19220.csv is DONE\n",
      "\n",
      "\n",
      "19229.csv is DONE\n",
      "\n",
      "\n",
      "19239.csv is DONE\n",
      "\n",
      "\n",
      "19240.csv is DONE\n",
      "\n",
      "\n",
      "19243.csv is DONE\n",
      "\n",
      "\n",
      "19246.csv is DONE\n",
      "\n",
      "\n",
      "19247.csv is DONE\n",
      "\n",
      "\n",
      "19255.csv is DONE\n",
      "\n",
      "\n",
      "19257.csv is DONE\n",
      "\n",
      "\n",
      "19289.csv is DONE\n",
      "\n",
      "\n",
      "19300.csv is DONE\n",
      "\n",
      "\n",
      "19301.csv is DONE\n",
      "\n",
      "\n",
      "19302.csv is DONE\n",
      "\n",
      "\n",
      "19462.csv is DONE\n",
      "\n",
      "\n",
      "19463.csv is DONE\n",
      "\n",
      "\n",
      "77818.csv is DONE\n",
      "\n",
      "\n",
      "77819.csv is DONE\n",
      "\n",
      "\n",
      "77895.csv is DONE\n"
     ]
    }
   ],
   "source": [
    "for dataframe in os.listdir(gsmap_dir):\n",
    "    \n",
    "    bigdf = pd.read_csv(fancy_dir + dataframe.split()[0], parse_dates=['date'])\n",
    "    gsdf = pd.read_csv(gsmap_dir + dataframe.split()[0], parse_dates=['date'])\n",
    "\n",
    "    temp = gsdf[['date', 'prcp']]\n",
    "    merged_df = pd.merge(bigdf, temp, on='date', how='left')\n",
    "    merged_df.rename(columns={'prcp': 'prcp_gsmap'}, inplace=True)\n",
    "    # print(merged_df)\n",
    "    print('\\n')\n",
    "\n",
    "    path = chirps_dir + dataframe.split()[0]\n",
    "    if os.path.exists(path):\n",
    "        chirpsdf = pd.read_csv(path, parse_dates=['date'])\n",
    "        final_df = pd.merge(merged_df, chirpsdf, on='date',how='left')\n",
    "        final_df.rename(columns={'precipitation':'prcp_chirps'}, inplace=True) \n",
    "        # print(final_df.head())\n",
    "        final_df[['basin_id', 'date', 'prcp_era', 'prcp_gsmap', 'prcp_chirps', 'temp_mean', 'temp_min', 'temp_max', 'dew_mean', 'wind_speed', 'vp1', 'vp2', 'srad_joules']].to_csv(fancy_dir + dataframe, index=False)\n",
    "    else :\n",
    "        merged_df['prcp_chirps'] = np.nan\n",
    "        merged_df[['basin_id', 'date', 'prcp_era', 'prcp_gsmap', 'prcp_chirps', 'temp_mean', 'temp_min', 'temp_max', 'dew_mean', 'wind_speed', 'vp1', 'vp2', 'srad_joules']].to_csv(fancy_dir + dataframe, index=False)\n",
    "\n",
    "    print(dataframe.split()[0] + \" is DONE\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "# import astral \n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "\n",
    "def daylight(date, lat, lon, timezone_str='Asia/Almaty'):\n",
    "    # Create a location object with the given latitude and longitude\n",
    "    location = LocationInfo(latitude=lat, longitude=lon)\n",
    "    \n",
    "    # Get the local timezone using the provided timezone string\n",
    "    timezone = pytz.timezone(timezone_str)\n",
    "    \n",
    "    # Combine the date with the minimum time (midnight) and localize it to the timezone\n",
    "    date_local = timezone.localize(datetime.combine(date, datetime.min.time()))\n",
    "    \n",
    "    try:\n",
    "        # Calculate the sunrise and sunset times for the location and date\n",
    "        s = sun(location.observer, date=date_local)\n",
    "        sunrise_local = s['sunrise'].astimezone(timezone)\n",
    "        sunset_local = s['sunset'].astimezone(timezone)\n",
    "        \n",
    "        # Calculate the daylight duration in seconds\n",
    "        daylight_duration = sunset_local - sunrise_local\n",
    "        daylight_seconds = daylight_duration.total_seconds()\n",
    "        \n",
    "        # Handle edge case where daylight duration is negative\n",
    "        if daylight_seconds < 0:\n",
    "            raise ValueError(f\"Negative daylight duration: {daylight_seconds} seconds (Sunrise: {sunrise_local}, Sunset: {sunset_local})\")\n",
    "        \n",
    "    except ValueError:\n",
    "        # Return -1 in case of an error (e.g., invalid location/date, polar night)\n",
    "        daylight_seconds = -1\n",
    "    \n",
    "    return daylight_seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df = pd.read_csv('selected_hydro_stations.csv')\n",
    "coord = {row['id']: [row['lng'], row['lat']] for _, row in coordinates_df.iterrows()}\n",
    "print(coord)\n",
    "\n",
    "\n",
    "def daylight_count(row):\n",
    "    return daylight(row['date'], coord[row['basin_id']][1], coord[row['basin_id']][0])\n",
    "\n",
    "for elem in os.listdir(era_dir):\n",
    "    df = pd.read_csv(era_dir + elem, parse_dates=['date'])\n",
    "    df['daylight'] = df.apply(daylight_count, axis = 1)\n",
    "    \n",
    "    # Replace -1 with NaN\n",
    "    df['daylight'] = df['daylight'].replace(-1, np.nan)\n",
    "\n",
    "    # Forward fill NaN values, propagating the previous day's valid value\n",
    "    df['daylight'] = df['daylight'].fillna(method='ffill')\n",
    "    \n",
    "    df['srad'] = df['srad_joules'] / df['daylight']\n",
    "    # print(df.head())\n",
    "    # break\n",
    "    df[['basin_id', 'date', 'prcp', 'temp_mean', 'temp_min', 'temp_max', 'dew_mean', 'u_comp_wind', 'v_comp_wind', 'srad_joules', 'daylight', 'srad']].to_csv(era_dir+elem, index=False)\n",
    "    print(elem + \" is Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11001.csv is DONE\n",
      "11063.csv is DONE\n",
      "11068.csv is DONE\n",
      "11077.csv is DONE\n",
      "11090.csv is DONE\n",
      "11094.csv is DONE\n",
      "11108.csv is DONE\n",
      "11117.csv is DONE\n",
      "11124.csv is DONE\n",
      "11126.csv is DONE\n",
      "11129.csv is DONE\n",
      "11131.csv is DONE\n",
      "11137.csv is DONE\n",
      "11139.csv is DONE\n",
      "11143.csv is DONE\n",
      "11146.csv is DONE\n",
      "11147.csv is DONE\n",
      "11157.csv is DONE\n",
      "11160.csv is DONE\n",
      "11163.csv is DONE\n",
      "11164.csv is DONE\n",
      "11170.csv is DONE\n",
      "11187.csv is DONE\n",
      "11188.csv is DONE\n",
      "11189.csv is DONE\n",
      "11199.csv is DONE\n",
      "11207.csv is DONE\n",
      "11219.csv is DONE\n",
      "11233.csv is DONE\n",
      "11242.csv is DONE\n",
      "11272.csv is DONE\n",
      "11275.csv is DONE\n",
      "11291.csv is DONE\n",
      "11293.csv is DONE\n",
      "11395.csv is DONE\n",
      "11397.csv is DONE\n",
      "11421.csv is DONE\n",
      "11424.csv is DONE\n",
      "11432.csv is DONE\n",
      "11433.csv is DONE\n",
      "11453.csv is DONE\n",
      "11461.csv is DONE\n",
      "11468.csv is DONE\n",
      "11469.csv is DONE\n",
      "11661.csv is DONE\n",
      "12001.csv is DONE\n",
      "12002.csv is DONE\n",
      "12008.csv is DONE\n",
      "12029.csv is DONE\n",
      "12031.csv is DONE\n",
      "12032.csv is DONE\n",
      "12072.csv is DONE\n",
      "12075.csv is DONE\n",
      "12564.csv is DONE\n",
      "13002.csv is DONE\n",
      "13005.csv is DONE\n",
      "13016.csv is DONE\n",
      "13029.csv is DONE\n",
      "13035.csv is DONE\n",
      "13038.csv is DONE\n",
      "13048.csv is DONE\n",
      "13061.csv is DONE\n",
      "13064.csv is DONE\n",
      "13090.csv is DONE\n",
      "13091.csv is DONE\n",
      "13095.csv is DONE\n",
      "13105.csv is DONE\n",
      "13115.csv is DONE\n",
      "13128.csv is DONE\n",
      "13142.csv is DONE\n",
      "13148.csv is DONE\n",
      "13198.csv is DONE\n",
      "13201.csv is DONE\n",
      "13221.csv is DONE\n",
      "19010.csv is DONE\n",
      "19013.csv is DONE\n",
      "19021.csv is DONE\n",
      "19022.csv is DONE\n",
      "19033.csv is DONE\n",
      "19034.csv is DONE\n",
      "19130.csv is DONE\n",
      "19180.csv is DONE\n",
      "19195.csv is DONE\n",
      "19196.csv is DONE\n",
      "19205.csv is DONE\n",
      "19208.csv is DONE\n",
      "19211.csv is DONE\n",
      "19218.csv is DONE\n",
      "19220.csv is DONE\n",
      "19229.csv is DONE\n",
      "19239.csv is DONE\n",
      "19240.csv is DONE\n",
      "19243.csv is DONE\n",
      "19246.csv is DONE\n",
      "19247.csv is DONE\n",
      "19255.csv is DONE\n",
      "19257.csv is DONE\n",
      "19289.csv is DONE\n",
      "19300.csv is DONE\n",
      "19301.csv is DONE\n",
      "19302.csv is DONE\n",
      "19462.csv is DONE\n",
      "19463.csv is DONE\n",
      "77818.csv is DONE\n",
      "77819.csv is DONE\n",
      "77895.csv is DONE\n"
     ]
    }
   ],
   "source": [
    "# Copying the srad from CAMELS_KZ dataset\n",
    "# it is computed from ERA5 Land \n",
    "# just realized how stupid this idea was: camels_kz has only 42 basins, while yours has 106 basins. ==> IDIOT! \n",
    "\n",
    "\n",
    "# camels_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/CAMELS_KZ/mean_basin_forcing/'\n",
    "\n",
    "for dataframe in os.listdir(era_dir):\n",
    "    final_df = pd.read_csv(fancy_dir + dataframe.split('_')[1], parse_dates=['date'])\n",
    "    df1 = pd.read_csv(era_dir + dataframe, parse_dates=['date'])\n",
    "    final_df['srad'] = df1['srad']\n",
    "\n",
    "    final_df[['basin_id', 'date', 'prcp_era', 'prcp_gsmap', 'prcp_chirps', 'temp_mean', 'temp_min', 'temp_max', 'dew_mean', 'wind_speed', 'vp1', 'vp2', 'srad']].to_csv(fancy_dir + dataframe.split('_')[1], index=False)\n",
    "    print(dataframe.split('_')[1] + \" is DONE\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11063 is DONE\n",
      "11068 is DONE\n",
      "11077 is DONE\n",
      "11090 is DONE\n",
      "11094 is DONE\n",
      "11108 is DONE\n",
      "11117 is DONE\n",
      "11124 is DONE\n",
      "11126 is DONE\n",
      "11129 is DONE\n",
      "11131 is DONE\n",
      "11137 is DONE\n",
      "11139 is DONE\n",
      "11143 is DONE\n",
      "11146 is DONE\n",
      "11147 is DONE\n",
      "11157 is DONE\n",
      "11160 is DONE\n",
      "11163 is DONE\n",
      "11164 is DONE\n",
      "11170 is DONE\n",
      "11187 is DONE\n",
      "11188 is DONE\n",
      "11189 is DONE\n",
      "11199 is DONE\n",
      "11207 is DONE\n",
      "11219 is DONE\n",
      "11233 is DONE\n",
      "11242 is DONE\n",
      "11272 is DONE\n",
      "11275 is DONE\n",
      "11291 is DONE\n",
      "11293 is DONE\n",
      "11395 is DONE\n",
      "11397 is DONE\n",
      "11421 is DONE\n",
      "11424 is DONE\n",
      "11432 is DONE\n",
      "11433 is DONE\n",
      "11453 is DONE\n",
      "11461 is DONE\n",
      "11468 is DONE\n",
      "11469 is DONE\n",
      "11661 is DONE\n",
      "12001 is DONE\n",
      "12002 is DONE\n",
      "12008 is DONE\n",
      "12029 is DONE\n",
      "12031 is DONE\n",
      "12032 is DONE\n",
      "12072 is DONE\n",
      "12075 is DONE\n",
      "12564 is DONE\n",
      "13002 is DONE\n",
      "13005 is DONE\n",
      "13016 is DONE\n",
      "13029 is DONE\n",
      "13035 is DONE\n",
      "13038 is DONE\n",
      "13048 is DONE\n",
      "13061 is DONE\n",
      "13064 is DONE\n",
      "13090 is DONE\n",
      "13091 is DONE\n",
      "13095 is DONE\n",
      "13105 is DONE\n",
      "13115 is DONE\n",
      "13128 is DONE\n",
      "13142 is DONE\n",
      "13148 is DONE\n",
      "13198 is DONE\n",
      "13201 is DONE\n",
      "13221 is DONE\n",
      "19010 is DONE\n",
      "19013 is DONE\n",
      "19021 is DONE\n",
      "19022 is DONE\n",
      "19033 is DONE\n",
      "19034 is DONE\n",
      "19130 is DONE\n",
      "19180 is DONE\n",
      "19195 is DONE\n",
      "19196 is DONE\n",
      "19205 is DONE\n",
      "19208 is DONE\n",
      "19211 is DONE\n",
      "19218 is DONE\n",
      "19220 is DONE\n",
      "19229 is DONE\n",
      "19239 is DONE\n",
      "19240 is DONE\n",
      "19243 is DONE\n",
      "19246 is DONE\n",
      "19247 is DONE\n",
      "19255 is DONE\n",
      "19257 is DONE\n",
      "19289 is DONE\n",
      "19300 is DONE\n",
      "19301 is DONE\n",
      "19302 is DONE\n",
      "19462 is DONE\n",
      "19463 is DONE\n",
      "77818 is DONE\n",
      "77819 is DONE\n",
      "77895 is DONE\n"
     ]
    }
   ],
   "source": [
    "mswep_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/mswep/'\n",
    "f_dir = 'C:/Users/User/Desktop/Nazarbayev University/ISSAI Summer 2024/analysis_fancy/fancy_dataset/fancy_meteo/'\n",
    "\n",
    "for csv in os.listdir(mswep_dir):\n",
    "    if (csv.split('_')[0] == '11001'):\n",
    "        continue\n",
    "    ms_df = pd.read_csv(mswep_dir + csv)\n",
    "    fancy_df = pd.read_csv(f_dir + csv.split('_')[0] + '.csv')\n",
    "    # print(ms_df.tail())\n",
    "    # print(fancy_df.tail())\n",
    "    # break\n",
    "    fancy_df['prcp_mswep'] = ms_df['AvgPrecip']\n",
    "    # print(fancy_df.tail())\n",
    "    fancy_df.rename(columns={'temp_mean': 't_mean', 'temp_min': 't_min', 'temp_max': 't_max'}, inplace=True)\n",
    "    # print(fancy_df.head())\n",
    "    # break\n",
    "    fancy_df[['basin_id', 'date', 'prcp_era', 'prcp_mswep', 'prcp_gsmap', 'prcp_chirps', 't_mean', 't_min', 't_max', 'dew_mean', 'wind_speed', 'vp1', 'vp2', 'srad']].to_csv(f_dir + csv.split('_')[0] + '.csv', index=False)\n",
    "    print(csv.split('_')[0] + \" is DONE\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
